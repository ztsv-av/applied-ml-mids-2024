{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6XZ55wHbdm5"
      },
      "source": [
        "# Part 1 of the Machine Learning Project\n",
        "\n",
        "## Preliminaries\n",
        "\n",
        "\n",
        "Before satring familiarize yourself with pandas reading the “10 minutes to pandas” tutorial: https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html\n",
        "\n",
        "Browse through the full pandas user guide when needed: https://pandas.pydata.org/pandas-docs/stable/user_guide/index.html\n",
        "\n",
        "\n",
        "## Load libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "L8jsxX6eaxL_"
      },
      "outputs": [],
      "source": [
        "# numpy and pandas for data manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# File system manangement\n",
        "import os\n",
        "\n",
        "# Suppress warnings\n",
        "#import warnings\n",
        "#warnings.filterwarnings('ignore')\n",
        "\n",
        "# matplotlib and seaborn for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctTp1HonbYpj"
      },
      "source": [
        "<p><img alt=\"Datasets\" src=\"https://storage.googleapis.com/kaggle-media/competitions/home-credit/home_credit.png\" align=\"left\" hspace=\"10px\" vspace=\"0px\"></p>\n",
        "\n",
        "\n",
        "<h1>Datasets</h1>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TAo_jy0PhBEY"
      },
      "outputs": [
        {
          "ename": "BadZipFile",
          "evalue": "File is not a zip file",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m src_bureau \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://docs.google.com/uc?export=download&id=18ycqN4m4zmoLvZHWIvYzF9SZiErAPeTi\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# If you cannot load the directly the csv from Google drive (Google restrictions), download them manually then change the path to load them locally\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m app_train \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m app_train\n",
            "File \u001b[1;32mc:\\Users\\Ant\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Ant\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32mc:\\Users\\Ant\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\Ant\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32mc:\\Users\\Ant\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py:784\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;66;03m# ZIP Compression\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m compression \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    781\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_BytesZipFile\" has incompatible type\u001b[39;00m\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# \"Union[str, BaseBuffer]\"; expected \"Union[Union[str, PathLike[str]],\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# ReadBuffer[bytes], WriteBuffer[bytes]]\"\u001b[39;00m\n\u001b[1;32m--> 784\u001b[0m     handle \u001b[38;5;241m=\u001b[39m _BytesZipFile(\n\u001b[0;32m    785\u001b[0m         handle, ioargs\u001b[38;5;241m.\u001b[39mmode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcompression_args  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    786\u001b[0m     )\n\u001b[0;32m    787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m handle\u001b[38;5;241m.\u001b[39mbuffer\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    788\u001b[0m         handles\u001b[38;5;241m.\u001b[39mappend(handle)\n",
            "File \u001b[1;32mc:\\Users\\Ant\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\common.py:1027\u001b[0m, in \u001b[0;36m_BytesZipFile.__init__\u001b[1;34m(self, file, mode, archive_name, **kwargs)\u001b[0m\n\u001b[0;32m   1024\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, zipfile\u001b[38;5;241m.\u001b[39mZIP_DEFLATED)\n\u001b[0;32m   1025\u001b[0m \u001b[38;5;66;03m# error: Incompatible types in assignment (expression has type \"ZipFile\",\u001b[39;00m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;66;03m# base class \"_BufferedWriter\" defined the type as \"BytesIO\")\u001b[39;00m\n\u001b[1;32m-> 1027\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer: zipfile\u001b[38;5;241m.\u001b[39mZipFile \u001b[38;5;241m=\u001b[39m zipfile\u001b[38;5;241m.\u001b[39mZipFile(  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m   1028\u001b[0m     file, mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1029\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\Ant\\AppData\\Local\\Programs\\Python\\Python39\\lib\\zipfile.py:1264\u001b[0m, in \u001b[0;36mZipFile.__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1263\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m-> 1264\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_RealGetContents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m   1266\u001b[0m         \u001b[38;5;66;03m# set the modified flag so central directory gets written\u001b[39;00m\n\u001b[0;32m   1267\u001b[0m         \u001b[38;5;66;03m# even if no files are added to the archive\u001b[39;00m\n\u001b[0;32m   1268\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_didModify \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Ant\\AppData\\Local\\Programs\\Python\\Python39\\lib\\zipfile.py:1331\u001b[0m, in \u001b[0;36mZipFile._RealGetContents\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m endrec:\n\u001b[1;32m-> 1331\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadZipFile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is not a zip file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdebug \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   1333\u001b[0m     \u001b[38;5;28mprint\u001b[39m(endrec)\n",
            "\u001b[1;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ],
      "source": [
        "## Change this part with your own dataset files\n",
        "\n",
        "data_folder = \"data/\"\n",
        "\n",
        "src_train = f\"{data_folder}application_train.csv.zip\" #'https://docs.google.com/uc?export=download&id=1TNRRGlws5vWKEum8v1PQrVq8PGacMT9Y'\n",
        "src_test = f\"{data_folder}application_test.csv.zip\" #'https://docs.google.com/uc?export=download&id=1IEUuu-Czdv2gsE8Q0EUtGvUelh2xUwN8'\n",
        "\n",
        "# src_previous = f\"{data_folder}bureau_balance.csv.zip\" #'https://docs.google.com/uc?export=download&id=15PuV3DpXii2FokryWCyxTS4HGUj4Kbmn'\n",
        "src_bureau = f\"{data_folder}bureau.csv.zip\" #'https://docs.google.com/uc?export=download&id=18ycqN4m4zmoLvZHWIvYzF9SZiErAPeTi'\n",
        "\n",
        "# If you cannot load the directly the csv from Google drive (Google restrictions), download them manually then change the path to load them locally\n",
        "\n",
        "app_train = pd.read_csv(src_train, compression=\"zip\")\n",
        "app_train\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPBTWB1ViFHe"
      },
      "source": [
        "<h1>Loading the datasets (2 pts)</h1>\n",
        "\n",
        "1. Similarly to the train set, load the test set, the bureau dataset and the past applications dataset.\n",
        "\n",
        "2. Display for each the number of rows and the number of columns\n",
        "\n",
        "*You will be evaluated as follow*\n",
        "* 1: Correct approach + code: 1pt\n",
        "* 2: Code: 1pts\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjoGTJvLiBPP"
      },
      "outputs": [],
      "source": [
        "#Your code here\n",
        "#The variables that should be implemented to store the data are: app_train, app_test, bureau, app_past\n",
        "\n",
        "\n",
        "# 1 - Loading the different datasets.\n",
        "app_test =\n",
        "bureau =\n",
        "app_past =\n",
        "\n",
        "# 2 - The number of rows and columns for each\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnMI0pRmkHzH"
      },
      "source": [
        "<h1> Feature Engineering</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuAAPVW1kH82"
      },
      "source": [
        "<h2>Missing values (9pts)</h2>\n",
        "\n",
        "\n",
        "**3.a**: What columns are missing the most values in app_test?\n",
        "\n",
        "**3.b**: What columns are missing the most values in bureau?\n",
        "\n",
        "**3.c**: What columns are missing the most values in app_past?\n",
        "\n",
        "4: Fix missing data in app_test dataset using categorization and/or simple imputation when appropriate. Be careful to the **data leakage** issue!\n",
        "\n",
        "*You will be evaluated as follow*\n",
        "* 3: Correct approach + code 2pts.\n",
        "* 4: Description of the approach 4pts. Code implementation of the approach 3pts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GCD-Tet5rKuq"
      },
      "outputs": [],
      "source": [
        "# 3\n",
        "\n",
        "## Your code here\n",
        "\n",
        "\n",
        "# 4: Fix missing data in app_test using categorization and/or simple imputation when appropriate. You should use *only* pandas and numpy here. You should *not* use sklearn (scikit-learn).\n",
        "\n",
        "## Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz6iD4S-rVUy"
      },
      "source": [
        "**4**: Describe your approach, including how you choose the technique to apply, and how you apply the technique (double click to edit a text cell)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRgq0O0R8Dql"
      },
      "source": [
        "## Class Imbalance (8 pts)\n",
        "\n",
        "5. Evaluate the class imbalance of the training set.\n",
        "\n",
        "6. **a** Fix the class imbalance with over/undersampling\n",
        "\n",
        " **b** Use the SMOTE algorithm to fix class imbalance\n",
        "\n",
        "*You will be evaluated as follow*\n",
        "* 5: Correct approach + code: 2ts\n",
        "* 6.a: code 3pt\n",
        "* 6.b: code 3pts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylyaMfXN8Kbd"
      },
      "outputs": [],
      "source": [
        "# 5 - value counts\n",
        "\n",
        "\n",
        "# 5 - histograms\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KP0jGTbSfQyb"
      },
      "source": [
        "**5**: Describe briefly your observation (double click to edit a text cell)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTyLbFbxgiD1"
      },
      "outputs": [],
      "source": [
        "# copy your current dataframe with its .copy() method. You should always use the copy() method if you want to keep the original dataframe untouched when you modify\n",
        "# this is a very common bug, so please read  https://www.statology.org/pandas-copy-dataframe/\n",
        "\n",
        "## Your code here\n",
        "app_train_original = ...\n",
        "\n",
        "\n",
        "# 6.a - fix imbalance with undersampling or oversampling\n",
        "# Implement undersampling or oversampling *without* external libraries, only the library provided to implement yourself the chosen solution.\n",
        "\n",
        "## Your code here\n",
        "\n",
        "\n",
        "# 6.b - fix balance with SMOTE on your previously copied dataframe\n",
        "# You can use any external libraries to use SMOTE. We recommend the imbalanced-learn package https://imbalanced-learn.org/stable/over_sampling.html\n",
        "# Make sure to select the appropriate SMOTE variant.\n",
        "\n",
        "\n",
        "## Your code here\n",
        "app_train_smote = ...\n",
        "\n",
        "\n",
        "# We will use the dataframe app_train from 6.a in the following"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h27ZdP7aloQb"
      },
      "source": [
        "<h2>Categorical features (9pts)</h2>\n",
        "\n",
        "In `app_test`\n",
        "\n",
        "**7a**: How will you transform the column NAME_HOUSING_TYPE in app_test be correctly handled by the model? How will you transform CODE_GENDER column?\n",
        "\n",
        "**7b**: How would you transform the column NAME_HOUSING_TYPE in app_test if you want only 3 categories? Use LabelEncoder to transform FLAG_OWN_CAR column.\n",
        "\n",
        "**7c**: In ORGANIZATION_TYPE, only keep the categories that appear in more than 10% of the dataset. Group other categories in one. What is the size of the dummy vector for ORGANIZATION_TYPE after this transformation?\n",
        "\n",
        "\n",
        "8: **In app_test, app_past and bureau,** transform all the categorical columns that you have not processed in 7 using One-hot encoding.\n",
        "\n",
        "*You will be evaluated as follow*\n",
        "* 7: Description of the approach 4pts. Code 3pts.\n",
        "* 8: Correct approach + code 2pts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shlk_faurPh6"
      },
      "outputs": [],
      "source": [
        "## Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufWJR8ScnHb4"
      },
      "source": [
        "<h2>Anomalies (7 pts)</h2>\n",
        "\n",
        "**In app_test**\n",
        "\n",
        "**9a**: Is there an anomaly with the column DEF_30_CNT_SOCIAL_CIRCLE? If so, how would you solve it?\n",
        "\n",
        "**9b**: Is there an anomaly with the column LANDAREA_AVG? If so, how would you solve it?\n",
        "\n",
        "**9c**: Is there an anomaly with the column AMT_INCOME_TOTAL? If so, how would you solve it?\n",
        "\n",
        "10: Fix the anomaly in DAYS_EMPLOYED?\n",
        "\n",
        "*You will be evaluated as follow*\n",
        "* 9: Description of the approach + code 5pts.\n",
        "* 10: code 2pts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5TcZk8Q5jQ-"
      },
      "outputs": [],
      "source": [
        "## Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DgQ2i5B25lRC"
      },
      "source": [
        "<h2>Correlations (9 pts)</h2>\n",
        "\n",
        "\n",
        "11: **In app_test**, remove the collinear features of the dataset. How did you choose the threshold?\n",
        "\n",
        "12: What features from bureau.csv could you use to improve the training set? Use the random forest model from the notebook of the Lecture to check if it actually improves the final model performance.\n",
        "\n",
        "*You will be evaluated as follow*\n",
        "* 11: Code 3pts. Threshold explanation 1pt.\n",
        "* 12: Description of the approach 1pt. Code implementation of the approach 2pts. Improved performance 2pts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uU1j3LW2S-ir"
      },
      "outputs": [],
      "source": [
        "## Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_fQJhfcyQWn"
      },
      "source": [
        "##  Class imbalance and model performances (6 points)\n",
        "\n",
        "\n",
        "**13**: Evaluate the other technique (SMOTE) to handeling imbalance data left in *6.b*. Does it makes a difference on the final model performance? Can you use the performance on the test set to choose which techniques to use? If not, what would you need to do so?\n",
        "\n",
        "*You will be evaluated as follow*\n",
        "* 13: Code 3pts. Explanation 3pts.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDR7b8VRyUkS"
      },
      "outputs": [],
      "source": [
        "## Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kxXg4CA3nPO"
      },
      "source": [
        "**13**: Answer the question here (double click to edit a text cell)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
